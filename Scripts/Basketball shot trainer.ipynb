{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f556a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import Image_Processing_Classes as ip\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import os\n",
    "import imutils\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import re\n",
    "from contextlib import contextmanager\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1442547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BST_Image_Proc:\n",
    "    #this class will serve as a way to incorporate multiple image processing libraries\n",
    "    def __init__(self, raw_frame=None, vid=None, codec=None, raw_writer=None, processed_writer=None):    \n",
    "        if vid==None:\n",
    "            self.vid = cv2.VideoCapture(0)\n",
    "        else:\n",
    "            self.vid = vid\n",
    "            \n",
    "        if codec==None:\n",
    "            self.codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        else:\n",
    "            self.codec = codec\n",
    "            \n",
    "        if raw_writer==None:\n",
    "            self.raw_writer = cv2.VideoWriter('output.avi', codec, 20.0, (640, 480))\n",
    "        else:\n",
    "            self.raw_writer = raw_writer\n",
    "            \n",
    "        if processed_writer==None:\n",
    "            self.processed_writer = cv2.VideoWriter('output.avi', codec, 20.0, (640, 480))\n",
    "        else:\n",
    "            self.processed_writer = processed_writer\n",
    "        \n",
    "\n",
    "        #creating mediapipe objects for finding body position\n",
    "        self.pose = mp.solutions.pose\n",
    "        self.mp_drawing = mp.solutions.drawing_utils \n",
    "        self.mp_styles = mp.solutions.drawing_styles\n",
    "        self.fps = self.vid.get(cv2.CAP_PROP_FPS)\n",
    "        self.raw_frames = []\n",
    "        self.raw_frame = raw_frame\n",
    "        self.processed_frames = []\n",
    "        self.process_frame = None\n",
    "\n",
    "        #getting deep neural network data for processing\n",
    "        self.initialize_yolo()\n",
    "        \n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "  \n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        del self\n",
    "        if exc_type is not None:\n",
    "            traceback.print_exception(exc_type, exc_value, tb)\n",
    "            # return False # uncomment to pass exception through\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def initialize_yolo(self):\n",
    "        yolo_dir = os.path.abspath(\"./yolo\")\n",
    "\n",
    "        # load the labels, weights, and config for the yolo model\n",
    "        weights_path = os.path.sep.join([yolo_dir, \"yolov3.weights\"])\n",
    "        config_path = os.path.sep.join([yolo_dir, \"yolov3.cfg\"])\n",
    "\n",
    "        # load the labels (as list), and model\n",
    "        self.yolo = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "        # get the output layers\n",
    "        self.layer_names = self.yolo.getLayerNames()\n",
    "        self.layer_names = [self.layer_names[i - 1] for i in self.yolo.getUnconnectedOutLayers()]\n",
    "        \n",
    "    def find_ball(self, confidence_threshold = 0.3):\n",
    "        frame = self.raw_frame\n",
    "        #method for detecting ball on image\n",
    "        #frame = imutils.resize(frame, width=500)\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "        self.yolo.setInput(blob)\n",
    "        layerOutputs = self.yolo.forward(self.layer_names)\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classIDs = []\n",
    "        for output in layerOutputs:\n",
    "            # loop over each of the detections\n",
    "            for detection in output:\n",
    "                # get the class id and confidence for the object\n",
    "                scores = detection[5:]\n",
    "                classID = np.argmax(scores)\n",
    "                confidence = scores[classID]\n",
    "                if confidence > confidence_threshold and classID == 32:\n",
    "                    # get the bounding box for the object\n",
    "                    (H, W) = frame.shape[:2]\n",
    "                    box = detection[0:4] * np.array([W, H, W, H])\n",
    "                    (x, y, width, height) = box.astype(\"int\")\n",
    "                    # update our list of bounding box coordinates, confidences, and class IDs\n",
    "                    boxes.append([x, y, width, height])\n",
    "                    confidences.append(float(confidence))\n",
    "                    classIDs.append(classID)\n",
    "        if len(confidences) > 0:\n",
    "            (x, y, w, h) = boxes[np.argmax(confidences)]\n",
    "            self.ball = {\n",
    "                'x':x,\n",
    "                'y':y,\n",
    "                'w':W,\n",
    "                'h':h\n",
    "            }\n",
    "        else:\n",
    "            self.ball = {\n",
    "                'x':0,\n",
    "                'y':0,\n",
    "                'w':0,\n",
    "                'h':0\n",
    "            }\n",
    "        return self.ball\n",
    "    \n",
    "    def get_body_vectors(self):\n",
    "        \n",
    "        frame = self.raw_frame\n",
    "        pose = self.pose.Pose(static_image_mode=True, min_detection_confidence=0.5, model_complexity=2)\n",
    "        '''\n",
    "        with self.pose.Pose(\n",
    "            static_image_mode=True, min_detection_confidence=0.5, model_complexity=2) as pose:\n",
    "            # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "        '''\n",
    "        self.pose_landmarks = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).pose_landmarks\n",
    "        #return self.pose_landmarks\n",
    "                 \n",
    "    def draw_on_image(self, ball=None, results=None):\n",
    "        frame = self.raw_frame\n",
    "        if results == None:\n",
    "            results = self.pose_landmarks\n",
    "        if ball == None:\n",
    "            ball = self.ball\n",
    "        annotated_frame = frame.copy()\n",
    "        cv2.circle(annotated_frame, \n",
    "                   center = (self.ball['x'], self.ball['y']), \n",
    "                   radius=int(self.ball['h']/2), color=(0,255,0), \n",
    "                   thickness=3)\n",
    "        if not self.pose_landmarks:\n",
    "            pass\n",
    "        else:\n",
    "            self.mp_drawing.draw_landmarks(\n",
    "                annotated_frame,\n",
    "                self.pose_landmarks,\n",
    "                self.pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=self.mp_styles.get_default_pose_landmarks_style())\n",
    "                #annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "        self.processed_frame = annotated_frame\n",
    "        del annotated_frame\n",
    "    \n",
    "    def save_frame(self):\n",
    "        self.raw_frames.append(self.frame.copy())\n",
    "        \n",
    "    def process_frames(self, raw_frames=None):\n",
    "        if raw_frames == None:\n",
    "            raw_frames = self.raw_frames\n",
    "        for frame in self.raw_frames:\n",
    "            self.frame = frame\n",
    "            #find the coordinates and size of the ball\n",
    "            self.find_ball()\n",
    "            #find the person in the image and define the location of limbs as vectors\n",
    "            self.get_body_vectors()\n",
    "            #draw circle on ball and lines for person limbs\n",
    "            self.draw_on_image()\n",
    "    \n",
    "    @contextmanager\n",
    "    def process_frame(self, save=False):\n",
    "        try:\n",
    "            #find the coordinates and size of the ball\n",
    "            self.find_ball()\n",
    "            #find the person in the image and define the location of limbs as vectors\n",
    "            self.get_body_vectors()\n",
    "            #draw circle on ball and lines for person limbs\n",
    "            self.draw_on_image()\n",
    "            if save == True:\n",
    "                self.write_processed_frame()\n",
    "            yield self.processed_frame\n",
    "        finally:\n",
    "            pass\n",
    "\n",
    "            \n",
    "            \n",
    "    def play_video(self):\n",
    "        for frame in self.processed_frames:\n",
    "            cv2.imshow('frame', frame)\n",
    "            cv2.waitKey(int(1000/self.fps))\n",
    "            \n",
    "    def write_raw_video(self):\n",
    "        for frame in self.raw_frames:\n",
    "            self.raw_writer.write(frame)\n",
    "        \n",
    "    def write_processed_frame(self):\n",
    "        self.processed_writer.write(self.processed_frame)    \n",
    "        \n",
    "    def write_processed_video(self):\n",
    "        for frame in self.processed_frames:\n",
    "            self.processed_writer.write(frame)\n",
    "            \n",
    "    def destroy_assets(self):\n",
    "        del self.pose_landmarks\n",
    "        del self.ball    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ea05debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "raw_writer = cv2.VideoWriter('clips/raw/raw_%02d.jpg', 0, 0, (640, 480))\n",
    "processed_writer = cv2.VideoWriter('clips/processed/processed_%02d.jpg', 0, 0, (640, 480))\n",
    "proc = BST_Image_Proc(vid=vid, codec=codec, raw_writer=raw_writer, processed_writer=processed_writer)\n",
    "quit = False\n",
    "loop_counter = 0\n",
    "while True:\n",
    "    loop_counter += 1\n",
    "    #read from webcam\n",
    "    ret, frame = proc.vid.read()\n",
    "    \n",
    "    #check to make sure there is an image\n",
    "    if ret:\n",
    "        #set the class attribute as the image from the webcam\n",
    "        proc.frame = frame\n",
    "        #save the frame for processing\n",
    "        proc.save_frame()       \n",
    "        #display image\n",
    "        cv2.imshow('frame', proc.frame)\n",
    "        cv2.waitKey(int(1000/proc.fps))\n",
    "    \n",
    "    if loop_counter > 100:\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2ed4b36a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16168/4157652071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBST_Image_Proc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessed_writer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprocessed_writer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#proc.process_frame(save=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#raw_writer = cv2.VideoWriter('clips/raw/raw_%02d.jpg', 0, 0, (640, 480))\n",
    "processed_writer = cv2.VideoWriter('clips/processed/processed_%02d.jpg', 0, 0, (640, 480))\n",
    "\n",
    "file_list = os.listdir(os.getcwd() + '/clips/raw')\n",
    "for image_file in file_list:\n",
    "    if image_file == 'raw_%02d.jpg':\n",
    "        continue\n",
    "    path = os.getcwd() + \"/clips/raw/\" + image_file\n",
    "    frame = cv2.imread(path)\n",
    "    proc = BST_Image_Proc(raw_frame=frame, processed_writer=processed_writer)\n",
    "    with proc.process_frame(save=True) as proc:\n",
    "        print(proc)\n",
    "        #proc.process_frame(save=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49156128",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "raw_writer = cv2.VideoWriter('clips/raw/raw_%02d.jpg', 0, 0, (640, 480))\n",
    "processed_writer = cv2.VideoWriter('clips/processed/processed_%02d.jpg', 0, 0, (640, 480))\n",
    "proc = BST_Image_Proc(vid=vid, codec=codec, raw_writer=raw_writer, processed_writer=processed_writer)\n",
    "quit = False\n",
    "loop_counter = 0\n",
    "while True:\n",
    "    loop_counter += 1\n",
    "    #read from webcam\n",
    "    ret, frame = proc.vid.read()\n",
    "    \n",
    "    #check to make sure there is an image\n",
    "    if ret:\n",
    "        #set the class attribute as the image from the webcam\n",
    "        proc.frame = frame\n",
    "        #save the frame for processing\n",
    "        proc.save_frame()       \n",
    "        #display image\n",
    "        cv2.imshow('frame', proc.frame)\n",
    "        cv2.waitKey(int(1000/proc.fps))\n",
    "    \n",
    "    if loop_counter > 100:\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "proc.write_raw_video()\n",
    "\n",
    "#process recorded frames to find vectors and ball      \n",
    "proc.process_frames(save=True)\n",
    "\n",
    "#display the video with the frames annotated\n",
    "proc.play_video()\n",
    "  \n",
    "# After the loop release the cap object\n",
    "#vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "proc.write_raw_video()\n",
    "proc.write_processed_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
